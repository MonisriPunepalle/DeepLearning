{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a84dc53d-f64a-4097-ae0b-51e4b9d04234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import re\n",
    "from transformers import CLIPProcessor, CLIPModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f30ad0-4c33-466f-97cd-35e37b8f63b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained CLIP model and tokenizer\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c761e3c8-0b1a-47a9-bb26-96b0ce6cf14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Preprocess the image\n",
    "image_path = 'receipt1.jpg'\n",
    "image = Image.open(image_path)\n",
    "inputs = processor(text=None, images=image, return_tensors=\"pt\")\n",
    "print(inputs)'''\n",
    "# Preprocess the image\n",
    "image_path = 'receipt.jpg'\n",
    "image = Image.open(image_path)\n",
    "image_input = processor(\n",
    "    images=image,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82825397-7df3-43a8-8e6f-e368d3f55e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Encode the image\n",
    "with torch.no_grad():\n",
    "    image_features = model.get_image_features(**inputs)'''\n",
    "# Encode the image\n",
    "with torch.no_grad():\n",
    "    image_features = model.get_image_features(**image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545e9615-0ced-4c4c-8f98-605250d3ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text prompt\n",
    "prompt = \"Total amount payable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d5cb49-ad60-43df-9173-8168117ee68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the prompt\n",
    "with torch.no_grad():\n",
    "    prompt_inputs = processor(text=prompt, return_tensors=\"pt\")\n",
    "    prompt_features = model.get_text_features(**prompt_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30af89a-bf37-40af-ab27-4c37e77d2071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarity scores between the image and the prompt\n",
    "with torch.no_grad():\n",
    "    similarity_scores = (100.0 * image_features @ prompt_features.T).softmax(dim=-1)\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3632b334-9d5c-4b49-83ba-3aaac8d42a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!']\n"
     ]
    }
   ],
   "source": [
    "# Get the top matching tokens\n",
    "tokens = []\n",
    "for i in similarity_scores.argsort(descending=True):\n",
    "    token = processor.tokenizer.decode(i).strip()\n",
    "    if len(token) > 0:\n",
    "        tokens.append(token)\n",
    "    if len(tokens) >= 5:\n",
    "        break\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b431d15-4913-4f5e-a712-6cf48d929919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the total cost from the tokens\n",
    "for token in tokens:\n",
    "    match = re.match(r'\\d+\\.\\d+', token)\n",
    "    if match is not None:\n",
    "        total_cost = float(match.group())\n",
    "        break\n",
    "else:\n",
    "    # Define total_cost if no match is found\n",
    "    total_cost = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0accf4d4-27fe-4144-9a11-cb183b9a689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total cost: {total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a32ee-9619-40bf-b492-a1f93a468de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c41261-3b93-4e4d-a16a-c92f65f97842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
